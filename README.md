# HarvardForest
Harvard Forest transcriptomics power analysis work.

I want to write power_analysis.py to be able to look at 2 files 'foo_R1.clean', and 'foo_R2.clean', determine which one is smaller, then calculate a given percentage of the smaller file, and say how many records that would be.  Then use that information to call sample_fastq.py which was written by someone else in response to a BioStars question, and it seems like it works and seems like it takes paired end data...  By works I mean actually randomly samples the fastq files instead of just taking the first 75% or whatever percentage necessary.  sample_fastq.py takes the two original files as the first two arguments and the number of files you want to subsample out of the original as the third optional argument.  Then because I want to do it several times, I've been having to edit the output file name in the sample_fastq.py program so it doesn't overwrite the first one for remaining iterations of subsampling.  I've been using 3 subsampling events of 75% so far, and I'd like to do 50% and 30% next and I'd like to automate it instead of continuing to do it one by one.  That's where power_analysis.py comes in.  After it comes out of sample_fastq.py, I then run SoapyTux_EKW on them to process them to the point where they're ready for visualization.  I know it's a lot of information, but thanks for any hints.  I've been feeling really stuck for the last couple of days with it.
